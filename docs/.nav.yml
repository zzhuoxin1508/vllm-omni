nav:
- Home: README.md
- User Guide:
  - Getting Started:
    - getting_started/quickstart.md
    - getting_started/installation/*
  - Serving:
    - OpenAI-Compatible API:
      - Image Generation: serving/image_generation_api.md
      - Image Edit: serving/image_edit_api.md
  - Examples:
    - examples/README.md
    - Offline Inference:
      - BAGEL-7B-MoT: user_guide/examples/offline_inference/bagel.md
      - Image-To-Image: user_guide/examples/offline_inference/image_to_image.md
      - Image-To-Video: user_guide/examples/offline_inference/image_to_video.md
      - LoRA Inference Examples: user_guide/examples/offline_inference/lora_inference.md
      - Qwen2.5-Omni: user_guide/examples/offline_inference/qwen2_5_omni.md
      - Qwen3-Omni: user_guide/examples/offline_inference/qwen3_omni.md
      - Qwen3-TTS Offline Inference: user_guide/examples/offline_inference/qwen3_tts.md
      - Text-To-Audio: user_guide/examples/offline_inference/text_to_audio.md
      - Text-To-Image: user_guide/examples/offline_inference/text_to_image.md
      - Text-To-Video: user_guide/examples/offline_inference/text_to_video.md
    - Online Serving:
      - BAGEL-7B-MoT: user_guide/examples/online_serving/bagel.md
      - Image-To-Image: user_guide/examples/online_serving/image_to_image.md
      - Online LoRA Inference (Diffusion): user_guide/examples/online_serving/lora_inference.md
      - Qwen2.5-Omni: user_guide/examples/online_serving/qwen2_5_omni.md
      - Qwen3-Omni: user_guide/examples/online_serving/qwen3_omni.md
      - Qwen3-TTS Online Serving: user_guide/examples/online_serving/qwen3_tts.md
      - Text-To-Image: user_guide/examples/online_serving/text_to_image.md
  - General:
    - usage/*
  - Configuration:
    - configuration/README.md
    - configuration/*
  - Models:
    - models/supported_models.md
  - Features:
    - Sleep Mode: features/sleep_mode.md
    - Diffusion Features:
      - Overview: user_guide/diffusion_acceleration.md
      - TeaCache: user_guide/diffusion/teacache.md
      - Cache-DiT: user_guide/diffusion/cache_dit_acceleration.md
      - Parallelism Acceleration: user_guide/diffusion/parallelism_acceleration.md
      - CPU Offloading: user_guide/diffusion/cpu_offload_diffusion.md
- Developer Guide:
  - General:
    - contributing/README.md
    - glob: contributing/*
      flatten_single_child_sections: true
  - Model Implementation:
    - contributing/model/README.md
    - contributing/model/adding_omni_model.md
    - contributing/model/adding_diffusion_model.md
  - CI: contributing/ci
  - Design Documents:
    - design/index.md
    - design/architecture_overview.md
    - Feature Design:
      - design/feature/disaggregated_inference.md
      - design/feature/ray_based_execution.md
      - design/feature/omni_connectors/
    - Module Design:
      - design/module/ar_module.md
      - design/module/dit_module.md
      - design/module/entrypoint_module.md
  - Docs Guide: contributing/DOCS_GUIDE.md
- API Reference:
  - api/README.md
  - api/vllm_omni
- CLI Reference: cli
- Community:
  - community/*
  - Slack: https://slack.vllm.ai
  - Blog: https://blog.vllm.ai
  - Forum: https://discuss.vllm.ai
